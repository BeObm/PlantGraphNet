{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "from utils import *\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Build the PyTorch Geometric dataset using grid-based approach\n",
    "def build_dataset(dataset_path, output_path, nb_per_class=200,apply_transform=True):\n",
    "    dataset = []\n",
    "    class_folders = [d for d in os.listdir(dataset_path) if os.path.isdir(os.path.join(dataset_path, d))]\n",
    "\n",
    "    for label, class_folder in enumerate(class_folders):\n",
    "        pbar = tqdm(len(class_folders))\n",
    "        pbar.set_description(f\"Contructing graph data for Class #{label}: {class_folder} ... \")\n",
    "        class_path = os.path.join(dataset_path, class_folder)\n",
    "        if nb_per_class==0:\n",
    "          image_files = shuffle_dataset([f for f in os.listdir(class_path) if f.lower().endswith(('.png', '.jpg', '.jpeg','.tiff'))])\n",
    "        else:\n",
    "          image_files = shuffle_dataset([f for f in os.listdir(class_path) if f.lower().endswith(('.png', '.jpg', '.jpeg','.tiff'))])[:nb_per_class]\n",
    "        a = 1\n",
    "        for img_file in image_files:\n",
    "            img_path = os.path.join(class_path, img_file)\n",
    "            data = image_to_graph(img_path, label,apply_transform)\n",
    "            dataset.append(data)\n",
    "            if a < 3:\n",
    "                print(f\"Graph {a} for Class #{label} ({class_folder}): {data} \\n\")\n",
    "                plot_image_with_nodes(img_path, data, f\"{config['param']['result_folder']}/ImageAndGraph/{label}/{a}\")\n",
    "                a += 1\n",
    "        pbar.set_description(f\"Contructed {len(image_files)} graphs  for Class #{label}: {class_folder} \")\n",
    "        pbar.update(1)\n",
    "    torch.save(dataset, output_path)\n",
    "\n",
    "\n",
    "def image_to_graph(img_path, label,apply_transforms=True):\n",
    "    img = Image.open(img_path).convert('RGB')\n",
    "\n",
    "    if apply_transforms:\n",
    "        transform_pipeline= transform(type_data=\"train\")\n",
    "        img = transform_pipeline(img)\n",
    "    else:\n",
    "        transform_pipeline = transform(type_data=\"test\")\n",
    "        img = transform_pipeline(img)\n",
    "        # img = torch.from_numpy(np.transpose(img, (2, 0, 1))).to(dtype=torch.float)\n",
    "    print(f\"Image shape: {img.shape}\")\n",
    "    x, edge_index = get_node_features_and_edge_list(img)\n",
    "    y = torch.tensor([label], dtype=torch.long)\n",
    "    return Data(x=x, edge_index=edge_index, y=y, image_features=img.view(-1, 3))\n",
    "\n",
    "\n",
    "def get_node_features_and_edge_list(image):\n",
    "    \"\"\"\n",
    "    Convert an image into a graph representation using an edge list.\n",
    "    Parameters:\n",
    "        image (torch.Tensor): An input image of shape (height, width, channels),\n",
    "                              where 'channels' is typically 3 for RGB images.\n",
    "    Returns:\n",
    "        edges (list of tuple): List of edges, where each edge is a tuple (node1, node2).\n",
    "        node_features (torch.Tensor): Node features of the graph of size (num_pixels, channels).\n",
    "    \"\"\"\n",
    "\n",
    "    image = validate_image(image)\n",
    "    channels, height, width = image.shape\n",
    "\n",
    "    # Flatten the image into a list of nodes\n",
    "    node_features = image.view(-1, channels)  # Shape: (num_pixels, channels)\n",
    "\n",
    "    # Create an edge list for the graph\n",
    "    edges = compute_edges(height, width)\n",
    "\n",
    "    return  node_features, edges\n",
    "\n",
    "\n",
    "def validate_image(image):\n",
    "\n",
    "    if image.dim() != 3:\n",
    "        raise ValueError(\"Input image must have 3 dimensions: (height, width, channels)\")\n",
    "    return image\n",
    "\n",
    "\n",
    "def compute_edges(height, width):\n",
    "    \"\"\"Generate an edge list for a graph based on 8-connectivity.\"\"\"\n",
    "    edges = []\n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            current_index = pixel_to_index(i, j, width)\n",
    "            neighbors = [\n",
    "                (i - 1, j),  # Top\n",
    "                (i + 1, j),  # Bottom\n",
    "                (i, j - 1),  # Left\n",
    "                (i, j + 1),  # Right\n",
    "                (i - 1, j - 1),  # Top-left\n",
    "                (i - 1, j + 1),  # Top-right\n",
    "                (i + 1, j - 1),  # Bottom-left\n",
    "                (i + 1, j + 1),  # Bottom-right\n",
    "            ]\n",
    "            # Collect valid edges\n",
    "            for ni, nj in neighbors:\n",
    "                if 0 <= ni < height and 0 <= nj < width:  # Ensure within bounds\n",
    "                    neighbor_index = pixel_to_index(ni, nj, width)\n",
    "                    edges.append((current_index, neighbor_index))\n",
    "    return torch.tensor(edges,dtype=torch.long)\n",
    "\n",
    "\n",
    "\n",
    "def pixel_to_index(x, y, width):\n",
    "    \"\"\"Convert 2D pixel coordinates to a flattened index.\"\"\"\n",
    "    return x * width + y\n",
    "\n"
   ],
   "id": "8136d12c91bac36",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from PIL import Image\n",
    "\n",
    "\n",
    "# Function to predict a single image\n",
    "def predict_single_image(model, image_path, transform, device, class_names):\n",
    "    \"\"\"\n",
    "    Predict the class of a single image using the trained model.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): Trained model.\n",
    "        image_path (str): Path to the test image.\n",
    "        transform (torchvision.transforms.Compose): Transformations to apply.\n",
    "        device (torch.device): Device to run the prediction on.\n",
    "        class_names (list): List of class names corresponding to the trained labels.\n",
    "\n",
    "    Returns:\n",
    "        str: Predicted class name.\n",
    "    \"\"\"\n",
    "    # Load the image\n",
    "    image = Image.open(image_path).convert(\"RGB\")  # Ensure image is RGB\n",
    "    image_tensor = transform(image).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "    # Move input to device\n",
    "    image_tensor = image_tensor.to(device)\n",
    "\n",
    "    # Set model to evaluation mode and perform inference\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image_tensor)\n",
    "        _, predicted = torch.max(outputs, 1)  # Get the index of the max log-probability\n",
    "\n",
    "    # Get the class name\n",
    "    predicted_class = class_names[predicted.item()]\n",
    "    return predicted_class\n"
   ],
   "id": "2e8fae36175dfd61",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from threading import Lock\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "\n",
    "lock = Lock()  # Lock for thread-safe I/O operations\n",
    "\n",
    "\n",
    "def build_dataset(dataset_path, output_path, nb_per_class=200, apply_transform=True):\n",
    "    IMAGE_EXTENSIONS = ('.png', '.jpg', '.jpeg', '.tiff')  # File extension constant\n",
    "    dataset = []\n",
    "    class_folders = [d for d in os.listdir(dataset_path) if os.path.isdir(os.path.join(dataset_path, d))]\n",
    "\n",
    "    def process_image(img_path, label, class_folder, graph_counter):\n",
    "        # Process an individual image\n",
    "        graph_data = image_to_graph(img_path, label, apply_transform)\n",
    "\n",
    "        # Lock for printing and plotting to avoid concurrency issues\n",
    "        with lock:\n",
    "            if graph_counter <= 2:\n",
    "                print(f\"Graph {graph_counter} for Class #{label} ({class_folder}): {graph_data} \\n\")\n",
    "                plot_image_with_nodes(\n",
    "                    img_path,\n",
    "                    graph_data,\n",
    "                    f\"{config['param']['result_folder']}/ImageAndGraph/{label}/{graph_counter}\"\n",
    "                )\n",
    "        return graph_data\n",
    "\n",
    "    def process_class_data(class_folder, label):\n",
    "        class_path = os.path.join(dataset_path, class_folder)\n",
    "        image_files = shuffle_dataset([\n",
    "            f for f in os.listdir(class_path) if f.lower().endswith(IMAGE_EXTENSIONS)\n",
    "        ])\n",
    "        if nb_per_class > 0:\n",
    "            image_files = image_files[:nb_per_class]\n",
    "\n",
    "        # Parallel processing of images in the class\n",
    "        with ProcessPoolExecutor() as executor:\n",
    "            results = list(tqdm(\n",
    "                executor.map(lambda img_file: process_image(\n",
    "                    os.path.join(class_path, img_file), label, class_folder, image_files.index(img_file) + 1),\n",
    "                             image_files\n",
    "                             ),\n",
    "                total=len(image_files),\n",
    "                desc=f\"Processing Class {label}\"\n",
    "            ))\n",
    "        return results\n",
    "\n",
    "    # Iterate over classes and process them\n",
    "    for label, class_folder in enumerate(tqdm(class_folders, desc=\"Processing classes\")):\n",
    "        class_results = process_class_data(class_folder, label)\n",
    "        dataset.extend(class_results)  # Aggregate results from parallel processing\n",
    "\n",
    "    # Save the dataset after processing\n",
    "    torch.save(dataset, output_path)\n",
    "\n",
    "\n"
   ],
   "id": "1f3b0dc458ba1e9e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T22:18:18.704039Z",
     "start_time": "2025-01-19T22:18:08.141633Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "\n",
    "# Define the GNN Model\n",
    "class YourGNNModel(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super(YourGNNModel, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.fc = torch.nn.Linear(hidden_channels * 2, out_channels)  # Adjust input due to concatenation\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # First convolutional layer\n",
    "        x1 = self.conv1(x, edge_index)\n",
    "        x1 = F.relu(x1)\n",
    "\n",
    "        # Second convolutional layer\n",
    "        x2 = self.conv2(x1, edge_index)\n",
    "        x2 = F.relu(x2)\n",
    "\n",
    "        # Concatenate tensors from both layers\n",
    "        x_concat = torch.cat([x1, x2], dim=1)\n",
    "\n",
    "        # Fully connected layer\n",
    "        out = self.fc(x_concat)\n",
    "        return F.log_softmax(out, dim=1)  # Log-softmax for classification\n",
    "\n",
    "\n",
    "# Create a dummy dataset\n",
    "def build_dummy_data():\n",
    "    \"\"\"\n",
    "    Create a simple example graph for testing the GNN model.\n",
    "    4 nodes with 2 classes and a basic edge structure.\n",
    "    Returns: Torch Geometric Data object\n",
    "    \"\"\"\n",
    "    # Node features (4 nodes, 3 input features)\n",
    "    x = torch.tensor([[1, 0, 0], [0, 1, 0], [0, 0, 1], [1, 1, 1]], dtype=torch.float)\n",
    "\n",
    "    # Edge list (connectivity of the graph: 0->1, 1->2, 2->3, 3->0)\n",
    "    edge_index = torch.tensor([\n",
    "        [0, 1, 2, 3, 0, 2],  # Source nodes\n",
    "        [1, 2, 3, 0, 2, 0]   # Target nodes\n",
    "    ], dtype=torch.long)\n",
    "\n",
    "    # Node labels (for 2 classes)\n",
    "    y = torch.tensor([0, 1, 0, 1], dtype=torch.long)\n",
    "\n",
    "    # Create the graph data\n",
    "    data = Data(x=x, edge_index=edge_index, y=y)\n",
    "    return data\n",
    "\n",
    "\n",
    "# Training the GNN model on dummy data\n",
    "def train_gnn():\n",
    "    # Hyperparameters\n",
    "    in_channels = 3  # Features per node\n",
    "    hidden_channels = 4  # Hidden layer size\n",
    "    out_channels = 2  # Number of output classes\n",
    "    epochs = 50\n",
    "    learning_rate = 0.01\n",
    "\n",
    "    # Model and optimizer\n",
    "    model = YourGNNModel(in_channels, hidden_channels, out_channels)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Create a dummy dataset\n",
    "    data = build_dummy_data()\n",
    "\n",
    "    # Training loop\n",
    "    model.train()  # Set the model to training mode\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()  # Reset gradients\n",
    "\n",
    "        # Forward pass\n",
    "        out = model(data.x, data.edge_index)\n",
    "\n",
    "        # Compute the loss (negative log likelihood loss for classification)\n",
    "        loss = F.nll_loss(out, data.y)\n",
    "        loss.backward()  # Backpropagate the gradients\n",
    "        optimizer.step()  # Update parameters with optimizer\n",
    "\n",
    "        # Print loss every 10 epochs\n",
    "        if epoch % 10 == 0 or epoch == epochs - 1:\n",
    "            print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.item()}\")\n",
    "\n",
    "    print(\"Training complete.\")\n",
    "\n",
    "\n",
    "train_gnn()"
   ],
   "id": "e95996dc86ee69c5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 0.7582110166549683\n",
      "Epoch 11/50, Loss: 0.6493818759918213\n",
      "Epoch 21/50, Loss: 0.622076153755188\n",
      "Epoch 31/50, Loss: 0.5875752568244934\n",
      "Epoch 41/50, Loss: 0.5498992204666138\n",
      "Epoch 50/50, Loss: 0.5072420239448547\n",
      "Training complete.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T16:16:05.051822Z",
     "start_time": "2025-01-21T16:16:05.035798Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "def transform(type_data=\"train\"):\n",
    "    # Common preprocessing steps\n",
    "    preprocessing = [\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ]\n",
    "\n",
    "    if type_data == \"train\":\n",
    "        # Additional augmentations for training\n",
    "        augmentations = [\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomRotation(45),\n",
    "            transforms.RandomResizedCrop(\n",
    "                size=(224, 224),\n",
    "                scale=(0.8, 1.0),\n",
    "                ratio=(0.9, 1.1),\n",
    "                interpolation=transforms.InterpolationMode.BILINEAR\n",
    "            )\n",
    "        ]\n",
    "        return transforms.Compose(augmentations + preprocessing)\n"
   ],
   "id": "26366d5f368cef0b",
   "outputs": [],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T16:16:05.634555Z",
     "start_time": "2025-01-21T16:16:05.574768Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "import torchvision.models as models\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "def build_graph_from_image_harris(image_path, label,label_name,apply_transforms=True, output_path=\"dataset/test_graph_data.pt\",k=0.04, threshold=0.005, edge_type='4-connectivity'):\n",
    "    \"\"\"\n",
    "    Build a PyTorch graph from an image based on Harris corner detection.\n",
    "\n",
    "    Args:\n",
    "        image_path (str): Path to the image.\n",
    "        k (float): Harris detector free parameter for detecting corners.\n",
    "        threshold (float): Threshold for detecting strong corners.\n",
    "        edge_type (str): Type of graph edges. Options: '4-connectivity', '8-connectivity'.\n",
    "\n",
    "    Returns:\n",
    "        torch_geometric.data.Data: PyTorch geometric data object.\n",
    "    \"\"\"\n",
    "    # Step 1: Load image\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    if image is None:\n",
    "        raise ValueError(f\"Unable to load image from {image_path}\")\n",
    "    image = cv2.resize(image, (128, 128))\n",
    "\n",
    "    height, width = image.shape\n",
    "\n",
    "    # Step 2: Apply Harris corner detection\n",
    "    harris_response = cv2.cornerHarris(image, blockSize=3, ksize=3, k=k)\n",
    "\n",
    "    # Step 3: Apply threshold to extract strong corners\n",
    "    corners = np.zeros_like(harris_response, dtype=np.uint8)\n",
    "    corners[harris_response > threshold * harris_response.max()] = 1\n",
    "\n",
    "    # Step 4: Extract (x, y) positions of corner points\n",
    "    corner_positions = np.argwhere(corners == 1)  # Get row, col indices\n",
    "    corner_indices = {tuple(pos): idx for idx, pos in enumerate(corner_positions)}\n",
    "    node_features = corner_positions  # Node features are the (x, y) positions\n",
    "\n",
    "    # Step 5: Create edges based on neighbor connectivity\n",
    "    edges = []\n",
    "    for pos in corner_positions:\n",
    "        i, j = pos\n",
    "\n",
    "        # Neighbor coordinate offsets for chosen connectivity\n",
    "        neighbors = []\n",
    "        if edge_type == '8-connectivity':\n",
    "            neighbors = [\n",
    "                (i - 1, j), (i + 1, j), (i, j - 1), (i, j + 1),\n",
    "                (i - 1, j - 1), (i - 1, j + 1), (i + 1, j - 1), (i + 1, j + 1)\n",
    "            ]\n",
    "        elif edge_type == '4-connectivity':\n",
    "            neighbors = [\n",
    "                (i - 1, j), (i + 1, j), (i, j - 1), (i, j + 1)\n",
    "            ]\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid edge_type {edge_type}\")\n",
    "\n",
    "        # Process each neighbor\n",
    "        for ni, nj in neighbors:\n",
    "            if 0 <= ni < height and 0 <= nj < width and corners[ni, nj] == 1:  # Within bounds and valid corner\n",
    "                edges.append((corner_indices[tuple(pos)], corner_indices[(ni, nj)]))\n",
    "\n",
    "    # Convert edges to PyTorch tensor\n",
    "    edge_index = torch.tensor(edges, dtype=torch.long).t() if edges else torch.empty((2, 0), dtype=torch.long)\n",
    "\n",
    "    # Convert corner positions to PyTorch tensor as node features\n",
    "    x = torch.tensor(node_features, dtype=torch.float)\n",
    "\n",
    "    foundation_model = models.densenet121(weights='DenseNet121_Weights.IMAGENET1K_V1')\n",
    "    feature_extractor = torch.nn.Sequential(*list(foundation_model.features.children()))\n",
    "    feature_extractor.eval()\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "\n",
    "    if apply_transforms:\n",
    "        transform_pipeline = transform(type_data=\"train\")\n",
    "        img = transform_pipeline(image).unsqueeze(dim=0)\n",
    "    else:\n",
    "        transform_pipeline = transform(type_data=\"test\")\n",
    "        img = transform_pipeline(image).unsqueeze(dim=0)\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        features = feature_extractor(img)\n",
    "\n",
    "    img_features = torch.flatten(features, start_dim=1)\n",
    "\n",
    "\n",
    "\n",
    "    # Return PyTorch geometric Data object\n",
    "    data = Data(x=x, edge_index=edge_index, y=label, image_features=img_features,label_name=label_name)\n",
    "    torch.save(data, output_path)\n",
    "\n",
    "    return data\n",
    "\n"
   ],
   "id": "58d97d4f0a3b1ba4",
   "outputs": [],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T16:16:16.820061Z",
     "start_time": "2025-01-21T16:16:16.793918Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def plot_image_with_nodes(img_path, data, output_folder=\"GraphImage\"):\n",
    "    # Create the output folder if it doesn't exist\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # Load the image\n",
    "    img = io.imread(img_path)\n",
    "\n",
    "    # Initialize the graph\n",
    "    G = nx.Graph()\n",
    "\n",
    "    for i, feat in enumerate(data.x.cpu().numpy()):\n",
    "        x=feat[0]\n",
    "        y=feat[1]\n",
    "        G.add_node(i, pos=(x, y))\n",
    "\n",
    "    for edge in data.edge_index.t().cpu().numpy():\n",
    "        G.add_edge(edge[0], edge[1])\n",
    "\n",
    "    # Create a plot\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.subplot(121)\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(122)\n",
    "    pos = nx.get_node_attributes(G, 'pos')\n",
    "    nx.draw(G, pos, with_labels=False, node_size=10, node_color='r')\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Extract the image name without extension and create the output path\n",
    "    img_name = os.path.splitext(os.path.basename(img_path))[0]\n",
    "    output_path = os.path.join(output_folder, \"graph.png\")\n",
    "\n",
    "    # Save the plot\n",
    "    plt.savefig(output_path, bbox_inches='tight')\n",
    "    plt.close()\n"
   ],
   "id": "71059d5a05363681",
   "outputs": [],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T16:16:18.481326Z",
     "start_time": "2025-01-21T16:16:17.580067Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Example usage\n",
    "im=r\"C:\\Users\\au783153\\Documents\\OBM\\CODES\\HeathlandSpeciesClassifier\\dataset\\images\\test\\amm\\im63_64_4.1.0.jpg\"\n",
    "graph_data = build_graph_from_image_harris(im,label=2, label_name=\"tree\", k=0.04, threshold=0.1)\n",
    "print(graph_data)\n",
    "plot_image_with_nodes(im, graph_data)"
   ],
   "id": "36bb57d9de77d55d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[536, 2], edge_index=[2, 1038], y=2, image_features=[1, 50176], label_name='tree')\n"
     ]
    }
   ],
   "execution_count": 50
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "f=torch.load(r\"C:\\Users\\au783153\\Documents\\OBM\\CODES\\HeathlandSpeciesClassifier\\dataset\\graphs\\grid\\train\\0_68.pt\")\n",
    "f"
   ],
   "id": "f5c6c439d80c9ec7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "8bd83f893e48be75"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
