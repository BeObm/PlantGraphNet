{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "from utils import *\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Build the PyTorch Geometric dataset using grid-based approach\n",
    "def build_dataset(dataset_path, output_path, nb_per_class=200,apply_transform=True):\n",
    "    dataset = []\n",
    "    class_folders = [d for d in os.listdir(dataset_path) if os.path.isdir(os.path.join(dataset_path, d))]\n",
    "\n",
    "    for label, class_folder in enumerate(class_folders):\n",
    "        pbar = tqdm(len(class_folders))\n",
    "        pbar.set_description(f\"Contructing graph data for Class #{label}: {class_folder} ... \")\n",
    "        class_path = os.path.join(dataset_path, class_folder)\n",
    "        if nb_per_class==0:\n",
    "          image_files = shuffle_dataset([f for f in os.listdir(class_path) if f.lower().endswith(('.png', '.jpg', '.jpeg','.tiff'))])\n",
    "        else:\n",
    "          image_files = shuffle_dataset([f for f in os.listdir(class_path) if f.lower().endswith(('.png', '.jpg', '.jpeg','.tiff'))])[:nb_per_class]\n",
    "        a = 1\n",
    "        for img_file in image_files:\n",
    "            img_path = os.path.join(class_path, img_file)\n",
    "            data = image_to_graph(img_path, label,apply_transform)\n",
    "            dataset.append(data)\n",
    "            if a < 3:\n",
    "                print(f\"Graph {a} for Class #{label} ({class_folder}): {data} \\n\")\n",
    "                plot_image_with_nodes(img_path, data, f\"{config['param']['result_folder']}/ImageAndGraph/{label}/{a}\")\n",
    "                a += 1\n",
    "        pbar.set_description(f\"Contructed {len(image_files)} graphs  for Class #{label}: {class_folder} \")\n",
    "        pbar.update(1)\n",
    "    torch.save(dataset, output_path)\n",
    "\n",
    "\n",
    "def image_to_graph(img_path, label,apply_transforms=True):\n",
    "    img = Image.open(img_path).convert('RGB')\n",
    "\n",
    "    if apply_transforms:\n",
    "        transform_pipeline= transform(type_data=\"train\")\n",
    "        img = transform_pipeline(img)\n",
    "    else:\n",
    "        transform_pipeline = transform(type_data=\"test\")\n",
    "        img = transform_pipeline(img)\n",
    "        # img = torch.from_numpy(np.transpose(img, (2, 0, 1))).to(dtype=torch.float)\n",
    "    print(f\"Image shape: {img.shape}\")\n",
    "    x, edge_index = get_node_features_and_edge_list(img)\n",
    "    y = torch.tensor([label], dtype=torch.long)\n",
    "    return Data(x=x, edge_index=edge_index, y=y, image_features=img.view(-1, 3))\n",
    "\n",
    "\n",
    "def get_node_features_and_edge_list(image):\n",
    "    \"\"\"\n",
    "    Convert an image into a graph representation using an edge list.\n",
    "    Parameters:\n",
    "        image (torch.Tensor): An input image of shape (height, width, channels),\n",
    "                              where 'channels' is typically 3 for RGB images.\n",
    "    Returns:\n",
    "        edges (list of tuple): List of edges, where each edge is a tuple (node1, node2).\n",
    "        node_features (torch.Tensor): Node features of the graph of size (num_pixels, channels).\n",
    "    \"\"\"\n",
    "\n",
    "    image = validate_image(image)\n",
    "    channels, height, width = image.shape\n",
    "\n",
    "    # Flatten the image into a list of nodes\n",
    "    node_features = image.view(-1, channels)  # Shape: (num_pixels, channels)\n",
    "\n",
    "    # Create an edge list for the graph\n",
    "    edges = compute_edges(height, width)\n",
    "\n",
    "    return  node_features, edges\n",
    "\n",
    "\n",
    "def validate_image(image):\n",
    "\n",
    "    if image.dim() != 3:\n",
    "        raise ValueError(\"Input image must have 3 dimensions: (height, width, channels)\")\n",
    "    return image\n",
    "\n",
    "\n",
    "def compute_edges(height, width):\n",
    "    \"\"\"Generate an edge list for a graph based on 8-connectivity.\"\"\"\n",
    "    edges = []\n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            current_index = pixel_to_index(i, j, width)\n",
    "            neighbors = [\n",
    "                (i - 1, j),  # Top\n",
    "                (i + 1, j),  # Bottom\n",
    "                (i, j - 1),  # Left\n",
    "                (i, j + 1),  # Right\n",
    "                (i - 1, j - 1),  # Top-left\n",
    "                (i - 1, j + 1),  # Top-right\n",
    "                (i + 1, j - 1),  # Bottom-left\n",
    "                (i + 1, j + 1),  # Bottom-right\n",
    "            ]\n",
    "            # Collect valid edges\n",
    "            for ni, nj in neighbors:\n",
    "                if 0 <= ni < height and 0 <= nj < width:  # Ensure within bounds\n",
    "                    neighbor_index = pixel_to_index(ni, nj, width)\n",
    "                    edges.append((current_index, neighbor_index))\n",
    "    return torch.tensor(edges,dtype=torch.long)\n",
    "\n",
    "\n",
    "\n",
    "def pixel_to_index(x, y, width):\n",
    "    \"\"\"Convert 2D pixel coordinates to a flattened index.\"\"\"\n",
    "    return x * width + y\n",
    "\n"
   ],
   "id": "8136d12c91bac36",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from PIL import Image\n",
    "\n",
    "\n",
    "# Function to predict a single image\n",
    "def predict_single_image(model, image_path, transform, device, class_names):\n",
    "    \"\"\"\n",
    "    Predict the class of a single image using the trained model.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): Trained model.\n",
    "        image_path (str): Path to the test image.\n",
    "        transform (torchvision.transforms.Compose): Transformations to apply.\n",
    "        device (torch.device): Device to run the prediction on.\n",
    "        class_names (list): List of class names corresponding to the trained labels.\n",
    "\n",
    "    Returns:\n",
    "        str: Predicted class name.\n",
    "    \"\"\"\n",
    "    # Load the image\n",
    "    image = Image.open(image_path).convert(\"RGB\")  # Ensure image is RGB\n",
    "    image_tensor = transform(image).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "    # Move input to device\n",
    "    image_tensor = image_tensor.to(device)\n",
    "\n",
    "    # Set model to evaluation mode and perform inference\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image_tensor)\n",
    "        _, predicted = torch.max(outputs, 1)  # Get the index of the max log-probability\n",
    "\n",
    "    # Get the class name\n",
    "    predicted_class = class_names[predicted.item()]\n",
    "    return predicted_class\n"
   ],
   "id": "2e8fae36175dfd61",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from threading import Lock\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "\n",
    "lock = Lock()  # Lock for thread-safe I/O operations\n",
    "\n",
    "\n",
    "def build_dataset(dataset_path, output_path, nb_per_class=200, apply_transform=True):\n",
    "    IMAGE_EXTENSIONS = ('.png', '.jpg', '.jpeg', '.tiff')  # File extension constant\n",
    "    dataset = []\n",
    "    class_folders = [d for d in os.listdir(dataset_path) if os.path.isdir(os.path.join(dataset_path, d))]\n",
    "\n",
    "    def process_image(img_path, label, class_folder, graph_counter):\n",
    "        # Process an individual image\n",
    "        graph_data = image_to_graph(img_path, label, apply_transform)\n",
    "\n",
    "        # Lock for printing and plotting to avoid concurrency issues\n",
    "        with lock:\n",
    "            if graph_counter <= 2:\n",
    "                print(f\"Graph {graph_counter} for Class #{label} ({class_folder}): {graph_data} \\n\")\n",
    "                plot_image_with_nodes(\n",
    "                    img_path,\n",
    "                    graph_data,\n",
    "                    f\"{config['param']['result_folder']}/ImageAndGraph/{label}/{graph_counter}\"\n",
    "                )\n",
    "        return graph_data\n",
    "\n",
    "    def process_class_data(class_folder, label):\n",
    "        class_path = os.path.join(dataset_path, class_folder)\n",
    "        image_files = shuffle_dataset([\n",
    "            f for f in os.listdir(class_path) if f.lower().endswith(IMAGE_EXTENSIONS)\n",
    "        ])\n",
    "        if nb_per_class > 0:\n",
    "            image_files = image_files[:nb_per_class]\n",
    "\n",
    "        # Parallel processing of images in the class\n",
    "        with ProcessPoolExecutor() as executor:\n",
    "            results = list(tqdm(\n",
    "                executor.map(lambda img_file: process_image(\n",
    "                    os.path.join(class_path, img_file), label, class_folder, image_files.index(img_file) + 1),\n",
    "                             image_files\n",
    "                             ),\n",
    "                total=len(image_files),\n",
    "                desc=f\"Processing Class {label}\"\n",
    "            ))\n",
    "        return results\n",
    "\n",
    "    # Iterate over classes and process them\n",
    "    for label, class_folder in enumerate(tqdm(class_folders, desc=\"Processing classes\")):\n",
    "        class_results = process_class_data(class_folder, label)\n",
    "        dataset.extend(class_results)  # Aggregate results from parallel processing\n",
    "\n",
    "    # Save the dataset after processing\n",
    "    torch.save(dataset, output_path)\n",
    "\n",
    "\n"
   ],
   "id": "1f3b0dc458ba1e9e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T22:18:18.704039Z",
     "start_time": "2025-01-19T22:18:08.141633Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "\n",
    "# Define the GNN Model\n",
    "class YourGNNModel(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super(YourGNNModel, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.fc = torch.nn.Linear(hidden_channels * 2, out_channels)  # Adjust input due to concatenation\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # First convolutional layer\n",
    "        x1 = self.conv1(x, edge_index)\n",
    "        x1 = F.relu(x1)\n",
    "\n",
    "        # Second convolutional layer\n",
    "        x2 = self.conv2(x1, edge_index)\n",
    "        x2 = F.relu(x2)\n",
    "\n",
    "        # Concatenate tensors from both layers\n",
    "        x_concat = torch.cat([x1, x2], dim=1)\n",
    "\n",
    "        # Fully connected layer\n",
    "        out = self.fc(x_concat)\n",
    "        return F.log_softmax(out, dim=1)  # Log-softmax for classification\n",
    "\n",
    "\n",
    "# Create a dummy dataset\n",
    "def build_dummy_data():\n",
    "    \"\"\"\n",
    "    Create a simple example graph for testing the GNN model.\n",
    "    4 nodes with 2 classes and a basic edge structure.\n",
    "    Returns: Torch Geometric Data object\n",
    "    \"\"\"\n",
    "    # Node features (4 nodes, 3 input features)\n",
    "    x = torch.tensor([[1, 0, 0], [0, 1, 0], [0, 0, 1], [1, 1, 1]], dtype=torch.float)\n",
    "\n",
    "    # Edge list (connectivity of the graph: 0->1, 1->2, 2->3, 3->0)\n",
    "    edge_index = torch.tensor([\n",
    "        [0, 1, 2, 3, 0, 2],  # Source nodes\n",
    "        [1, 2, 3, 0, 2, 0]   # Target nodes\n",
    "    ], dtype=torch.long)\n",
    "\n",
    "    # Node labels (for 2 classes)\n",
    "    y = torch.tensor([0, 1, 0, 1], dtype=torch.long)\n",
    "\n",
    "    # Create the graph data\n",
    "    data = Data(x=x, edge_index=edge_index, y=y)\n",
    "    return data\n",
    "\n",
    "\n",
    "# Training the GNN model on dummy data\n",
    "def train_gnn():\n",
    "    # Hyperparameters\n",
    "    in_channels = 3  # Features per node\n",
    "    hidden_channels = 4  # Hidden layer size\n",
    "    out_channels = 2  # Number of output classes\n",
    "    epochs = 50\n",
    "    learning_rate = 0.01\n",
    "\n",
    "    # Model and optimizer\n",
    "    model = YourGNNModel(in_channels, hidden_channels, out_channels)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Create a dummy dataset\n",
    "    data = build_dummy_data()\n",
    "\n",
    "    # Training loop\n",
    "    model.train()  # Set the model to training mode\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()  # Reset gradients\n",
    "\n",
    "        # Forward pass\n",
    "        out = model(data.x, data.edge_index)\n",
    "\n",
    "        # Compute the loss (negative log likelihood loss for classification)\n",
    "        loss = F.nll_loss(out, data.y)\n",
    "        loss.backward()  # Backpropagate the gradients\n",
    "        optimizer.step()  # Update parameters with optimizer\n",
    "\n",
    "        # Print loss every 10 epochs\n",
    "        if epoch % 10 == 0 or epoch == epochs - 1:\n",
    "            print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.item()}\")\n",
    "\n",
    "    print(\"Training complete.\")\n",
    "\n",
    "\n",
    "train_gnn()"
   ],
   "id": "e95996dc86ee69c5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 0.7582110166549683\n",
      "Epoch 11/50, Loss: 0.6493818759918213\n",
      "Epoch 21/50, Loss: 0.622076153755188\n",
      "Epoch 31/50, Loss: 0.5875752568244934\n",
      "Epoch 41/50, Loss: 0.5498992204666138\n",
      "Epoch 50/50, Loss: 0.5072420239448547\n",
      "Training complete.\n"
     ]
    }
   ],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
