{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "from utils import *\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Build the PyTorch Geometric dataset using grid-based approach\n",
    "def build_dataset(dataset_path, output_path, nb_per_class=200,apply_transform=True):\n",
    "    dataset = []\n",
    "    class_folders = [d for d in os.listdir(dataset_path) if os.path.isdir(os.path.join(dataset_path, d))]\n",
    "\n",
    "    for label, class_folder in enumerate(class_folders):\n",
    "        pbar = tqdm(len(class_folders))\n",
    "        pbar.set_description(f\"Contructing graph data for Class #{label}: {class_folder} ... \")\n",
    "        class_path = os.path.join(dataset_path, class_folder)\n",
    "        if nb_per_class==0:\n",
    "          image_files = shuffle_dataset([f for f in os.listdir(class_path) if f.lower().endswith(('.png', '.jpg', '.jpeg','.tiff'))])\n",
    "        else:\n",
    "          image_files = shuffle_dataset([f for f in os.listdir(class_path) if f.lower().endswith(('.png', '.jpg', '.jpeg','.tiff'))])[:nb_per_class]\n",
    "        a = 1\n",
    "        for img_file in image_files:\n",
    "            img_path = os.path.join(class_path, img_file)\n",
    "            data = image_to_graph(img_path, label,apply_transform)\n",
    "            dataset.append(data)\n",
    "            if a < 3:\n",
    "                print(f\"Graph {a} for Class #{label} ({class_folder}): {data} \\n\")\n",
    "                plot_image_with_nodes(img_path, data, f\"{config['param']['result_folder']}/ImageAndGraph/{label}/{a}\")\n",
    "                a += 1\n",
    "        pbar.set_description(f\"Contructed {len(image_files)} graphs  for Class #{label}: {class_folder} \")\n",
    "        pbar.update(1)\n",
    "    torch.save(dataset, output_path)\n",
    "\n",
    "\n",
    "def image_to_graph(img_path, label,apply_transforms=True):\n",
    "    img = Image.open(img_path).convert('RGB')\n",
    "\n",
    "    if apply_transforms:\n",
    "        transform_pipeline= transform(type_data=\"train\")\n",
    "        img = transform_pipeline(img)\n",
    "    else:\n",
    "        transform_pipeline = transform(type_data=\"test\")\n",
    "        img = transform_pipeline(img)\n",
    "        # img = torch.from_numpy(np.transpose(img, (2, 0, 1))).to(dtype=torch.float)\n",
    "    print(f\"Image shape: {img.shape}\")\n",
    "    x, edge_index = get_node_features_and_edge_list(img)\n",
    "    y = torch.tensor([label], dtype=torch.long)\n",
    "    return Data(x=x, edge_index=edge_index, y=y, image_features=img.view(-1, 3))\n",
    "\n",
    "\n",
    "def get_node_features_and_edge_list(image):\n",
    "    \"\"\"\n",
    "    Convert an image into a graph representation using an edge list.\n",
    "    Parameters:\n",
    "        image (torch.Tensor): An input image of shape (height, width, channels),\n",
    "                              where 'channels' is typically 3 for RGB images.\n",
    "    Returns:\n",
    "        edges (list of tuple): List of edges, where each edge is a tuple (node1, node2).\n",
    "        node_features (torch.Tensor): Node features of the graph of size (num_pixels, channels).\n",
    "    \"\"\"\n",
    "\n",
    "    image = validate_image(image)\n",
    "    channels, height, width = image.shape\n",
    "\n",
    "    # Flatten the image into a list of nodes\n",
    "    node_features = image.view(-1, channels)  # Shape: (num_pixels, channels)\n",
    "\n",
    "    # Create an edge list for the graph\n",
    "    edges = compute_edges(height, width)\n",
    "\n",
    "    return  node_features, edges\n",
    "\n",
    "\n",
    "def validate_image(image):\n",
    "\n",
    "    if image.dim() != 3:\n",
    "        raise ValueError(\"Input image must have 3 dimensions: (height, width, channels)\")\n",
    "    return image\n",
    "\n",
    "\n",
    "def compute_edges(height, width):\n",
    "    \"\"\"Generate an edge list for a graph based on 8-connectivity.\"\"\"\n",
    "    edges = []\n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            current_index = pixel_to_index(i, j, width)\n",
    "            neighbors = [\n",
    "                (i - 1, j),  # Top\n",
    "                (i + 1, j),  # Bottom\n",
    "                (i, j - 1),  # Left\n",
    "                (i, j + 1),  # Right\n",
    "                (i - 1, j - 1),  # Top-left\n",
    "                (i - 1, j + 1),  # Top-right\n",
    "                (i + 1, j - 1),  # Bottom-left\n",
    "                (i + 1, j + 1),  # Bottom-right\n",
    "            ]\n",
    "            # Collect valid edges\n",
    "            for ni, nj in neighbors:\n",
    "                if 0 <= ni < height and 0 <= nj < width:  # Ensure within bounds\n",
    "                    neighbor_index = pixel_to_index(ni, nj, width)\n",
    "                    edges.append((current_index, neighbor_index))\n",
    "    return torch.tensor(edges,dtype=torch.long)\n",
    "\n",
    "\n",
    "\n",
    "def pixel_to_index(x, y, width):\n",
    "    \"\"\"Convert 2D pixel coordinates to a flattened index.\"\"\"\n",
    "    return x * width + y\n",
    "\n"
   ],
   "id": "8136d12c91bac36",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from PIL import Image\n",
    "\n",
    "\n",
    "# Function to predict a single image\n",
    "def predict_single_image(model, image_path, transform, device, class_names):\n",
    "    \"\"\"\n",
    "    Predict the class of a single image using the trained model.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): Trained model.\n",
    "        image_path (str): Path to the test image.\n",
    "        transform (torchvision.transforms.Compose): Transformations to apply.\n",
    "        device (torch.device): Device to run the prediction on.\n",
    "        class_names (list): List of class names corresponding to the trained labels.\n",
    "\n",
    "    Returns:\n",
    "        str: Predicted class name.\n",
    "    \"\"\"\n",
    "    # Load the image\n",
    "    image = Image.open(image_path).convert(\"RGB\")  # Ensure image is RGB\n",
    "    image_tensor = transform(image).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "    # Move input to device\n",
    "    image_tensor = image_tensor.to(device)\n",
    "\n",
    "    # Set model to evaluation mode and perform inference\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image_tensor)\n",
    "        _, predicted = torch.max(outputs, 1)  # Get the index of the max log-probability\n",
    "\n",
    "    # Get the class name\n",
    "    predicted_class = class_names[predicted.item()]\n",
    "    return predicted_class\n"
   ],
   "id": "2e8fae36175dfd61",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from threading import Lock\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "\n",
    "lock = Lock()  # Lock for thread-safe I/O operations\n",
    "\n",
    "\n",
    "def build_dataset(dataset_path, output_path, nb_per_class=200, apply_transform=True):\n",
    "    IMAGE_EXTENSIONS = ('.png', '.jpg', '.jpeg', '.tiff')  # File extension constant\n",
    "    dataset = []\n",
    "    class_folders = [d for d in os.listdir(dataset_path) if os.path.isdir(os.path.join(dataset_path, d))]\n",
    "\n",
    "    def process_image(img_path, label, class_folder, graph_counter):\n",
    "        # Process an individual image\n",
    "        graph_data = image_to_graph(img_path, label, apply_transform)\n",
    "\n",
    "        # Lock for printing and plotting to avoid concurrency issues\n",
    "        with lock:\n",
    "            if graph_counter <= 2:\n",
    "                print(f\"Graph {graph_counter} for Class #{label} ({class_folder}): {graph_data} \\n\")\n",
    "                plot_image_with_nodes(\n",
    "                    img_path,\n",
    "                    graph_data,\n",
    "                    f\"{config['param']['result_folder']}/ImageAndGraph/{label}/{graph_counter}\"\n",
    "                )\n",
    "        return graph_data\n",
    "\n",
    "    def process_class_data(class_folder, label):\n",
    "        class_path = os.path.join(dataset_path, class_folder)\n",
    "        image_files = shuffle_dataset([\n",
    "            f for f in os.listdir(class_path) if f.lower().endswith(IMAGE_EXTENSIONS)\n",
    "        ])\n",
    "        if nb_per_class > 0:\n",
    "            image_files = image_files[:nb_per_class]\n",
    "\n",
    "        # Parallel processing of images in the class\n",
    "        with ProcessPoolExecutor() as executor:\n",
    "            results = list(tqdm(\n",
    "                executor.map(lambda img_file: process_image(\n",
    "                    os.path.join(class_path, img_file), label, class_folder, image_files.index(img_file) + 1),\n",
    "                             image_files\n",
    "                             ),\n",
    "                total=len(image_files),\n",
    "                desc=f\"Processing Class {label}\"\n",
    "            ))\n",
    "        return results\n",
    "\n",
    "    # Iterate over classes and process them\n",
    "    for label, class_folder in enumerate(tqdm(class_folders, desc=\"Processing classes\")):\n",
    "        class_results = process_class_data(class_folder, label)\n",
    "        dataset.extend(class_results)  # Aggregate results from parallel processing\n",
    "\n",
    "    # Save the dataset after processing\n",
    "    torch.save(dataset, output_path)\n",
    "\n",
    "\n"
   ],
   "id": "1f3b0dc458ba1e9e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
